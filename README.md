<p align="center">
  <img src="https://github.com/Jingkou1012/LLM-Collection/blob/main/Title-Img.jpg">
</p>

## LLM-Paper

> The limits of my language mean the limites of my world. - Ludwig Wittgenstein

This repository serves as a central hub for all things related to Large Language Models (LLMs). Whether you‚Äôre a researcher, developer, or simply curious about LLMs, you‚Äôll find valuable content here to enhance your understanding and work with these remarkable language models. 

---
## üéì Overview
- 230331 - RUCAIBox - Survey - A Survey of Large Language Models - [arXiv](https://arxiv.org/abs/2303.18223)
---
## Natural Language Processing
-
---
## üëë Transformer Related
- 170612 - Google - Transformer - Attention is All You Need - [arXiv](https://arxiv.org/abs/1706.03762)
- 181011 - Google - BERT - Pre-Training of Deep Bidirectional Transformers for Language Understanding - [arXiv](https://arxiv.org/abs/1810.04805)
- 200526 - Facebook - DETR - End-to-End Object Detection with Transformers - [arXiv](https://arxiv.org/abs/2005.12872)
- 201022 - Google - ViT - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale - [arXiv](https://arxiv.org/abs/2010.11929)
---
## GPT
- 180611 - GPT - Improving Language Understanding by Generative Pre-Training - [report](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)
- 190214 - GPT-2 - Language Models are Unsupervised Multitask Learners - [report](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- 200528 - GPT-3 - Language Models are Few-Shot Learners - [arXiv](https://arxiv.org/abs/2005.14165)
- 230315 - GPT-4 - GPT-4 Technical Report - [arXiv](https://arxiv.org/abs/2303.08774)
---
##
- 
- 
- 220304 - OpenAI - InstructGPT - Training Language Models to Follow Instructions with Human Feedback - [arXiv](https://arxiv.org/abs/2203.02155)
- 
- 230925 - OpenAI - GPT-4V - GPT-4V(ision) System Card - [report](https://cdn.openai.com/papers/GPTV_System_Card.pdf)
- 240513 - OpenAI - GPT-4o - Hello GPT-4o - [page](https://openai.com/index/hello-gpt-4o/)
- 240718 - OpenAi - GPT-4o mini - GPT-4o mini: Advancing Cost-Efficient Intelligence - [page](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
---
## Llama
- 230227 - Meta - Llama - Open and Efficient Foundation Language Models - [arXiv](https://arxiv.org/abs/2302.13971)
- 230718 - Meta - Llama 2 - Open Foundation and Fine-Tuned Chat Models - [arXiv](https://arxiv.org/abs/2307.09288)
- 240418 - Meta - Llama 3 - Introducing Meta Llama 3: The most capable openly available LLM to date - [blog](https://ai.meta.com/blog/meta-llama-3/)
- 240723 - Meta - Llama 3.1 - The Llama 3 Herd of Models - [blog](https://ai.meta.com/blog/meta-llama-3-1/) [paper](https://scontent.fsin15-2.fna.fbcdn.net/v/t39.2365-6/452387774_1036916434819166_4173978747091533306_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=t6egZJ8QdI4Q7kNvgFtFzvs&_nc_ht=scontent.fsin15-2.fna&oh=00_AYB-GFK6fEfINdSp2aOXtidS6BdWj-eRNVdnni0UD70p3Q&oe=66A67B0D)
---
## üß† Large Language Model
- 210226 - OpenAI - CLIP - Learning Transferable Visual Models From Natural Language Supervision - [arXiv](https://arxiv.org/abs/2103.00020)
- 231219 - Google - Gemini - A Family of Highly Capable Multimodal Models - [arXiv](https://arxiv.org/abs/2312.11805)
- 240221 - Google - Gemma - Open Models Based on Gemini Research and Technology - [report](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)
- 240308 - Google - Gemini 1.5 - Unlocking Multimodal Understanding across Millions of Tokens of Context - [arXiv](https://arxiv.org/abs/2403.05530)
- 240627 - Google - Gemma 2 - Improving Open Language Models at a Practical Size - [report](https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf)
---
## üéá Feature
- 220128 - Google - Chain of Thought - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models - [arXiv](https://arxiv.org/abs/2201.11903)
---
## üìè Fine-Tuning
- 190202 - Google - Adapter Tuning - Parameter-Efficient Transfer Learning for NLP - [arXiv](https://arxiv.org/abs/1902.00751)
- 210101 - Stanford University - Prefix Tuning - Optimizing Continuous Prompts for Generation - [arXiv](https://arxiv.org/abs/2101.00190)
- 210418 - Google - Prompt Tuning - The Power of Scale for Parameter-Efficient Prompt Tuning - [arXiv](https://arxiv.org/abs/2104.08691)
- 210617 - Microsoft - LoRA - Low-Rank Adaptation of Large Language Models - [arXiv](https://arxiv.org/abs/2106.09685)
---
## Quantization
- 230523 - University of Washington - QLoRA - Efficient Finetuning of Quantized LLMs - [arXiv](https://arxiv.org/abs/2305.14314)
---
## üë®‚Äçüè´ Reinforcement Learning from Human Feedback
- 170612 - OpenAI & Google - Reinforcement Learning - Deep Reinforcement Learning from Human Preferences - [arXiv](https://arxiv.org/abs/1706.03741)
- 170720 - OpenAI - Proximal Policy Optimization - Proximal Policy Optimization Algorithms - [arXiv](https://arxiv.org/abs/1707.06347)
- 200902 - OpenAI - Human Feedback - Learning to Summarize from Human Feedback - [arXiv](https://arxiv.org/abs/2009.01325)
---
## üìö Retrieval Augmented Generation
- 200522 - Facebook - RAG - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks - [arXiv](https://arxiv.org/abs/2005.11401)
- 240424 - Microsoft - Graph RAG - From Local to Global: A Graph RAG Approach to Query-Focused Summarization - [arXiv](https://arxiv.org/abs/2404.16130)
---
## üì∑ Vision Large Model
- 230417 - Haotian Liu - LLaVA - Visual Instruction Tuning - [arXiv](https://arxiv.org/abs/2304.08485)
- 231005 - Haotian Liu - LLaVA 1.5 - Improved Baselines with Visual Instruction Tuning - [arXiv](https://arxiv.org/abs/2310.03744)
- 240130 - Haotian Liu - LLaVA-NeXT - Improved Reasoning, OCR, and World Knowledge - [blog](https://llava-vl.github.io/blog/2024-01-30-llava-next/)
- 240514 - Google - PaliGemma - Google's Cutting-Edge Open Vision Language Model - [blog](https://huggingface.co/blog/paligemma)
---
## üöó Autonomous Driving
- 221220 - OpenDriveLab - UniAD - Planning-Oriented Autonomous Driving - [arXiv](https://arxiv.org/abs/2212.10156)
- 240219 - Tsinghua - DriveVLM - The Convergence of Autonomous Driving and Large Vision-Language Models - [arXiv](https://arxiv.org/abs/2402.12289)
---
## üí≠ Deep Dive
- Lil'Log - [blog](https://lilianweng.github.io/)
- Open LLM Leaderboard - [HF](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)
---
## ‚ô•Ô∏è Contributing

This project holds great significance for me, and I‚Äôm constantly seeking ways to improve it. If you have ideas, fixes, or even just suggestions, please share them! I‚Äôm open to discussing any pull requests, especially if we need to align them with the LLM‚Äôs goals.

Thansk a lot!

---
## ‚≠ê Star History
[![Star History Chart](https://api.star-history.com/svg?repos=Jingkou1012/LLM-Paper&type=Date)](https://star-history.com/#Jingkou1012/LLM-Paper&Date)
